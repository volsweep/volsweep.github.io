{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEC 2018 Campaign Finance: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state\n",
    "\n",
    "previously in politics\n",
    "\n",
    "proportion individ contrib from in-state\n",
    "\n",
    "party of prev officeholder \n",
    "\n",
    "primary results (is it open bc primary challenger beat incumbent)\n",
    "\n",
    "force predict one winner per race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from copy import deepcopy\n",
    "from itertools import combinations \n",
    "from matplotlib import patheffects as path_effects\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'position'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1720a6246b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# include only house elections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'H'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'position'"
     ]
    }
   ],
   "source": [
    "df_orig = pd.read_csv('data/04/df_cleaned_04b.csv')\n",
    "\n",
    "# include only house elections\n",
    "df_orig = df_orig[df_orig['position'] == 'H']\n",
    "print(len(df_orig))\n",
    "\n",
    "# exclude races where Third party won\n",
    "df_orig = df_orig[df_orig['contest'] != 'MP_00']\n",
    "print(len(df_orig))\n",
    "\n",
    "# exclude Third Party candidates for modeling for now\n",
    "df_orig = df_orig[df_orig['cand_pty_affiliation'] != 'Third party']\n",
    "print(len(df_orig))\n",
    "\n",
    "# exclude open seat races; model requires one incumbent and one challenger\n",
    "df_orig = df_orig[df_orig['cand_ici'] != 'O']\n",
    "print(len(df_orig))\n",
    "\n",
    "# exclude solo candidates\n",
    "solos = list(df_orig['contest'].value_counts()[df_orig['contest'].value_counts() == 1].index)\n",
    "for which in solos:\n",
    "    df_orig = df_orig[df_orig['contest'] != which]\n",
    "print(len(df_orig))\n",
    "\n",
    "# exclude races with more than one candidate from each party\n",
    "drops = []\n",
    "for race in list(df_orig['contest'].value_counts().index):\n",
    "    lil_df = df_orig[df_orig['contest'] == race]\n",
    "    orig = len(lil_df)\n",
    "    lil_df.drop_duplicates(['cand_pty_affiliation'], inplace = True)\n",
    "    new = len(lil_df)\n",
    "    if orig != new:\n",
    "        drops.append(race)\n",
    "        print(race)\n",
    "        \n",
    "mask = [False if df_orig.loc[i, 'contest'] in drops else True for i in list(df_orig.index)]\n",
    "df_orig = df_orig[mask]\n",
    "print(len(df_orig))\n",
    "\n",
    "# exclude races with more than one incumbent (i.e. gerrymandering cases)\n",
    "drops = []\n",
    "for race in list(df_orig['contest'].value_counts().index):\n",
    "    lil_df = df_orig[df_orig['contest'] == race]\n",
    "    orig = len(lil_df)\n",
    "    lil_df.drop_duplicates(['cand_ici'], inplace = True)\n",
    "    new = len(lil_df)\n",
    "    if orig != new:\n",
    "        drops.append(race)\n",
    "        print(race)\n",
    "        \n",
    "mask = [False if df_orig.loc[i, 'contest'] in drops else True for i in list(df_orig.index)]\n",
    "df_orig = df_orig[mask]\n",
    "print(len(df_orig))\n",
    "    \n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demog_df = pd.read_csv('data/07/demo_dict.csv')\n",
    "demog_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['noncismale'] = [\n",
    "    list(demog_df.loc[demog_df['cand_id'] == df_orig.loc[i, 'cand_id'], 'noncismale'].values)[0] \\\n",
    "    for i in list(df_orig.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_orig.drop([\n",
    "    'cand_id',\n",
    "    'cand_name',\n",
    "    'cvg_end_dt',\n",
    "    'cand_class', \n",
    "#     'contest', # keep for join later\n",
    "    'cand_office_district',\n",
    "    'cand_office_st',\n",
    "    'ttl_disb',\n",
    "    'coh_cop',\n",
    "    'cand_loan_repay',\n",
    "    'other_loan_repay',\n",
    "    'indiv_refunds',\n",
    "    'cmte_refunds',\n",
    "    'trans_to_auth',\n",
    "    'debts_owed_by', # include? or time machine issue\n",
    "    'position',\n",
    "], axis = 1)\n",
    "\n",
    "if len(df.isnull().sum()[df.isnull().sum() > 0].sort_values()) == 0:\n",
    "    print('no nulls')\n",
    "else:\n",
    "    print('check nulls')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[x for x in df.columns if 'loan' not in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummify = [\n",
    "    'cand_ici',\n",
    "    'cand_pty_affiliation',\n",
    "#     'position'\n",
    "]\n",
    "\n",
    "for col in dummify:\n",
    "    df = pd.concat([\n",
    "        df.drop([col], axis = 1), \n",
    "        pd.get_dummies(df[col])\n",
    "    ], axis = 1)\n",
    "    \n",
    "df.rename(columns={\n",
    "    'C' : 'challenger',\n",
    "    'I' : 'incumbent',\n",
    "    'O' : 'open seat',\n",
    "#     'H' : 'House',\n",
    "#     'S' : 'Senate',\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "republicans = df[df['Republican'] == 1]\n",
    "republicans.columns = [x + ' (R)' if x != 'contest' else x for x in republicans.columns]\n",
    "republicans.set_index('contest', inplace = True)\n",
    "\n",
    "democrats = df[df['Republican'] == 0]\n",
    "democrats.columns = [x + ' (D)' if x != 'contest' else x for x in democrats.columns]\n",
    "democrats.set_index('contest', inplace = True)\n",
    "\n",
    "pre_dfs = republicans.join(democrats, on = 'contest')\n",
    "pre_dfs.reset_index(drop = False, inplace = True)\n",
    "\n",
    "pre_dfs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dfs['r:d_funding_ratio'] = pre_dfs['ttl_receipts (R)']/pre_dfs['ttl_receipts (D)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list(pre_dfs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contin_cols = [\n",
    "    'ttl_receipts (R)',\n",
    "    'trans_from_auth (R)',\n",
    "    'coh_bop (R)',\n",
    "    'cand_contrib (R)',\n",
    "#     'cand_loans (R)',\n",
    "#     'other_loans (R)',\n",
    "    'ttl_indiv_contrib (R)',\n",
    "    'other_pol_cmte_contrib (R)',\n",
    "    'pol_pty_contrib (R)',\n",
    "    'comm_ct (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'trans_from_auth (D)',\n",
    "    'coh_bop (D)',\n",
    "    'cand_contrib (D)',\n",
    "#     'cand_loans (D)',\n",
    "#     'other_loans (D)',\n",
    "    'ttl_indiv_contrib (D)',\n",
    "    'other_pol_cmte_contrib (D)',\n",
    "    'pol_pty_contrib (D)',\n",
    "    'comm_ct (D)',\n",
    "    'r:d_funding_ratio',\n",
    "    \n",
    "]\n",
    "\n",
    "contin = pre_dfs[contin_cols]\n",
    "\n",
    "contin_s = pd.DataFrame(\n",
    "    MinMaxScaler().fit_transform(contin), \n",
    "    index = pre_dfs.index, \n",
    "    columns = contin_cols,\n",
    ")\n",
    "\n",
    "the_rest = [x for x in pre_dfs.columns if x not in contin_s.columns]\n",
    "\n",
    "dfs = pd.concat([contin_s, pre_dfs[the_rest]], axis = 1)\n",
    "\n",
    "# dfs.columns = [x for x in pre_dfs.columns if x != 'contest']\n",
    "\n",
    "# can use once missing values filled in\n",
    "# dfs.drop([\n",
    "#     'nonwhite (R)', \n",
    "#     'nonwhite (D)',\n",
    "# ], axis = 1, inplace = True)\n",
    "\n",
    "dfs.columns = [x.replace('Republican', 'republican').replace('Democrat', 'democrat') for x in dfs.columns]\n",
    "\n",
    "dfs = dfs[sorted(dfs.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.drop([\n",
    "    'challenger (D)',\n",
    "    'challenger (R)',\n",
    "    'contest',\n",
    "    'democrat (D)',\n",
    "    'democrat (R)',\n",
    "    'incumbent (D)',\n",
    "    'maxfunding_flag (D)',\n",
    "    'maxfunding_flag (R)',\n",
    "    'republican (D)',\n",
    "    'republican (R)',\n",
    "    'winner_flag (D)',\n",
    "    \n",
    "], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partisan donors -- only gave to one party\n",
    "dfs.sum()[dfs.sum() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = dfs.sum()[dfs.sum() == 0].index\n",
    "\n",
    "for which in drops:\n",
    "    dfs.drop(which, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 12))\n",
    "corr_mat = np.tril(dfs.corr(), k = -1)\n",
    "sns.heatmap(corr_mat, cmap = 'PRGn', vmin = -1, vmax = 1)\n",
    "plt.title('2018 U.S. House of Representatives elections:\\nFeature correlation', fontsize = 14)\n",
    "plt.xticks(\n",
    "    np.arange(0.5, len(dfs.columns), 1), \n",
    "    dfs.columns, \n",
    "    fontsize = 6, \n",
    "    rotation = 90\n",
    ")\n",
    "plt.yticks(\n",
    "    np.arange(0.5, len(dfs.columns), 1), \n",
    "    dfs.columns, \n",
    "    fontsize = 6, \n",
    "    rotation = 0\n",
    ")\n",
    "plt.xlim([0, len(dfs.columns)])\n",
    "plt.ylim([len(dfs.columns), 0])\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = deepcopy(dfs)\n",
    "X.drop(['winner_flag (R)'], axis = 1, inplace = True)\n",
    "\n",
    "# target is whether incumbent wins\n",
    "y = dfs[['winner_flag (R)']]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X[y['winner_flag (R)'] == 1], \n",
    "    y[y['winner_flag (R)'] == 1], \n",
    "    random_state = 421, \n",
    "    test_size = 0.33\n",
    ")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X[y['winner_flag (R)'] == 0], \n",
    "    y[y['winner_flag (R)'] == 0], \n",
    "    random_state = 421, \n",
    "    test_size = 0.33\n",
    ")\n",
    "\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "\n",
    "all_four = [\n",
    "    [X_train1, X_train2],\n",
    "    [X_test1, X_test2],\n",
    "    [y_train1, y_train2],\n",
    "    [y_test1, y_test2],\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    X_train = pd.concat([X_train, all_four[0][i]], axis = 0)\n",
    "    X_test = pd.concat([X_test, all_four[1][i]], axis = 0)\n",
    "    y_train = pd.concat([y_train, all_four[2][i]], axis = 0)\n",
    "    y_test = pd.concat([y_test, all_four[3][i]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    confmat, \n",
    "    title = 'Confusion Matrix', \n",
    "    labels = ['Win', 'Loss'], \n",
    "    cmap = plt.cm.Blues,\n",
    "):\n",
    "\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.imshow(\n",
    "        confmat, \n",
    "        interpolation = 'nearest', \n",
    "        cmap = cmap, \n",
    "    )\n",
    "\n",
    "    plt.grid(b = False)\n",
    "\n",
    "    width, height = confmat.shape\n",
    "    \n",
    "    tick_marks = np.arange(width)\n",
    "    plt.xticks(tick_marks, labels, fontsize = 14)\n",
    "    plt.yticks(tick_marks, labels, fontsize = 14)\n",
    "    plt.scatter(0, 0, color = (0,0,0,0))\n",
    "\n",
    "    plt.title(title, fontsize = 14)\n",
    "    plt.ylabel('Actual', fontsize = 14)\n",
    "    plt.xlabel('Prediction', fontsize = 14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(\n",
    "                str(confmat[x][y]), \n",
    "                xy = (y, x), \n",
    "                horizontalalignment = 'center', \n",
    "                verticalalignment = 'center', \n",
    "                color = 'white', \n",
    "                fontsize = 40,\n",
    "            ).set_path_effects(\n",
    "                [\n",
    "                    path_effects.Stroke(linewidth = 1, \n",
    "                                        foreground = 'black'\n",
    "                                       ), \n",
    "                    path_effects.Normal()\n",
    "                ]\n",
    "            )\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_inc = [1 if (dfs.loc[i, 'incumbent (R)'] == 1) else 0 for i in list(dfs.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(dfs['winner_flag (R)'], y_pred_inc),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Naïve model confusion matrix\\n--> choose incumbent',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred_inc), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "inc_wrong = inc_y[inc_y['test'] != inc_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[inc_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fund = [1 if (pre_dfs.loc[i, 'r:d_funding_ratio'] > 1) else 0 for i in list(dfs.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(dfs['winner_flag (R)'], y_pred_fund),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Naïve model confusion matrix\\n--> choose higher funding',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred_fund), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "fund_wrong = fund_y[fund_y['test'] != fund_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[fund_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(cv = 11, random_state = 421)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Logistic regression confusion matrix',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "lr_wrong = lr_y[lr_y['test'] != lr_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[lr_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(zip(X, lr.coef_[0]), columns = ['col', 'coef'])\n",
    "coefs['abs_coef'] = [abs(x) for x in coefs['coef']]\n",
    "\n",
    "coefs.sort_values(['abs_coef'], ascending = False, inplace = True)\n",
    "coefs['color'] = (coefs['coef'] == coefs['abs_coef'])\n",
    "coefs['color'] = ['green' if x == True else 'purple' for x in coefs['color']]\n",
    "coefs.drop(['abs_coef'], axis = 1, inplace = True)\n",
    "coefs = coefs[::-1]\n",
    "coefs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 24))\n",
    "plt.barh(\n",
    "    coefs.index, \n",
    "    coefs['coef'].apply(lambda x: abs(x)), \n",
    "    color = coefs['color'], \n",
    "    alpha = 0.8\n",
    ")\n",
    "\n",
    "plt.title('2018 U.S. House of Representatives elections:\\n\\\n",
    "Logistic regression feature importance', fontsize = 14)\n",
    "plt.ylabel('Feature', fontsize = 12)\n",
    "plt.yticks(range(len(coefs)), coefs['col'].values)\n",
    "plt.xlabel('Coefficient', fontsize = 12)\n",
    "# plt.xticks()\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=421)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Random forest confusion matrix',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "rfc_wrong = rfc_y[rfc_y['test'] != rfc_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[rfc_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(zip(X, rfc.feature_importances_), columns = ['col', 'coef'])\n",
    "coefs['abs_coef'] = [abs(x) for x in coefs['coef']]\n",
    "\n",
    "coefs.sort_values(['abs_coef'], ascending = False, inplace = True)\n",
    "coefs['color'] = (coefs['coef'] == coefs['abs_coef'])\n",
    "coefs['color'] = ['green' if x == True else 'purple' for x in coefs['color']]\n",
    "coefs.drop(['abs_coef'], axis = 1, inplace = True)\n",
    "coefs = coefs[::-1]\n",
    "coefs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 24))\n",
    "plt.barh(\n",
    "    coefs.index, \n",
    "    coefs['coef'].apply(lambda x: abs(x)), \n",
    "    color = coefs['color'], \n",
    "    alpha = 0.8\n",
    ")\n",
    "\n",
    "plt.title('2018 House of Representatives elections:\\n\\\n",
    "Random forest feature importance', fontsize = 14)\n",
    "plt.ylabel('Feature', fontsize = 12)\n",
    "plt.yticks(range(len(coefs)), coefs['col'].values)\n",
    "plt.xlabel('Importance', fontsize = 12)\n",
    "plt.xticks(rotation = -45)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.LinearSVC(random_state = 421)\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "SVM.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\nSVM confusion matrix',\n",
    "    labels = ['Win', 'Loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "svm_wrong = svm_y[svm_y['test'] != svm_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[svm_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MLPClassifier()\n",
    "\n",
    "NN.fit(X_train, y_train)\n",
    "y_pred = NN.predict(X_test)\n",
    "NN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\nNN confusion matrix',\n",
    "    labels = ['Win', 'Loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "nn_wrong = nn_y[nn_y['test'] != nn_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[nn_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "dfspc = dfs.drop(['winner_flag (R)'], axis = 1)\n",
    "\n",
    "pca = PCA(n_components = len(dfspc.columns))\n",
    "\n",
    "pc = pca.fit(dfspc)\n",
    "# pcdf = pd.DataFrame(\n",
    "#     data = pc, \n",
    "# #     columns = ['principal component 1', 'principal component 2'], \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(dfspc.columns)), pc.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpc = deepcopy(pcdf)\n",
    "\n",
    "# target is whether incumbent wins\n",
    "ypc = dfs[['winner_flag (R)']]\n",
    "\n",
    "Xpc_train1, Xpc_test1, ypc_train1, ypc_test1 = train_test_split(\n",
    "    Xpc[ypc['winner_flag (R)'] == 1], \n",
    "    ypc[ypc['winner_flag (R)'] == 1], \n",
    "    random_state = 421, \n",
    "    test_size = 0.33\n",
    ")\n",
    "\n",
    "Xpc_train2, Xpc_test2, ypc_train2, ypc_test2 = train_test_split(\n",
    "    Xpc[ypc['winner_flag (R)'] == 0], \n",
    "    ypc[ypc['winner_flag (R)'] == 0], \n",
    "    random_state = 421, \n",
    "    test_size = 0.33\n",
    ")\n",
    "\n",
    "Xpc_train = pd.DataFrame()\n",
    "Xpc_test = pd.DataFrame()\n",
    "ypc_train = pd.DataFrame()\n",
    "ypc_test = pd.DataFrame()\n",
    "\n",
    "all_four = [\n",
    "    [Xpc_train1, Xpc_train2],\n",
    "    [Xpc_test1, Xpc_test2],\n",
    "    [ypc_train1, ypc_train2],\n",
    "    [ypc_test1, ypc_test2],\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    Xpc_train = pd.concat([Xpc_train, all_four[0][i]], axis = 0)\n",
    "    Xpc_test = pd.concat([Xpc_test, all_four[1][i]], axis = 0)\n",
    "    ypc_train = pd.concat([ypc_train, all_four[2][i]], axis = 0)\n",
    "    ypc_test = pd.concat([ypc_test, all_four[3][i]], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpc = LogisticRegressionCV(cv = 11, random_state = 421)\n",
    "\n",
    "lrpc.fit(Xpc_train, ypc_train)\n",
    "y_pred = lrpc.predict(Xpc_test)\n",
    "lrpc.score(Xpc_test, ypc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Logistic regression confusion matrix',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "lr_wrong = lr_y[lr_y['test'] != lr_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[lr_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(zip(Xpc, lrpc.coef_[0]), columns = ['col', 'coef'])\n",
    "coefs['abs_coef'] = [abs(x) for x in coefs['coef']]\n",
    "\n",
    "coefs.sort_values(['abs_coef'], ascending = False, inplace = True)\n",
    "coefs['color'] = (coefs['coef'] == coefs['abs_coef'])\n",
    "coefs['color'] = ['green' if x == True else 'purple' for x in coefs['color']]\n",
    "coefs.drop(['abs_coef'], axis = 1, inplace = True)\n",
    "coefs = coefs[::-1]\n",
    "coefs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 24))\n",
    "plt.barh(\n",
    "    coefs.index, \n",
    "    coefs['coef'].apply(lambda x: abs(x)), \n",
    "    color = coefs['color'], \n",
    "    alpha = 0.8\n",
    ")\n",
    "\n",
    "plt.title('2018 U.S. House of Representatives elections:\\n\\\n",
    "Logistic regression feature importance', fontsize = 14)\n",
    "plt.ylabel('Feature', fontsize = 12)\n",
    "plt.yticks(range(len(coefs)), coefs['col'].values)\n",
    "plt.xlabel('Coefficient', fontsize = 12)\n",
    "# plt.xticks()\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcpc = RandomForestClassifier(random_state=421)\n",
    "\n",
    "rfcpc.fit(Xpc_train, ypc_train)\n",
    "ypc_pred = rfcpc.predict(Xpc_test)\n",
    "rfcpc.score(Xpc_test, ypc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(ypc_test, ypc_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Random forest confusion matrix',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcpc_y = pd.DataFrame(\n",
    "    zip(ypc_test['winner_flag (R)'], ypc_pred), \n",
    "    index = ypc_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "rfcpc_wrong = rfcpc_y[rfcpc_y['test'] != rfcpc_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[rfcpc_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(zip(Xpc, rfcpc.feature_importances_), columns = ['col', 'coef'])\n",
    "coefs['abs_coef'] = [abs(x) for x in coefs['coef']]\n",
    "\n",
    "coefs.sort_values(['abs_coef'], ascending = False, inplace = True)\n",
    "coefs['color'] = (coefs['coef'] == coefs['abs_coef'])\n",
    "coefs['color'] = ['green' if x == True else 'purple' for x in coefs['color']]\n",
    "coefs.drop(['abs_coef'], axis = 1, inplace = True)\n",
    "coefs = coefs[::-1]\n",
    "coefs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 24))\n",
    "plt.barh(\n",
    "    coefs.index, \n",
    "    coefs['coef'].apply(lambda x: abs(x)), \n",
    "    color = coefs['color'], \n",
    "    alpha = 0.8\n",
    ")\n",
    "\n",
    "plt.title('2018 House of Representatives elections:\\n\\\n",
    "Random forest feature importance', fontsize = 14)\n",
    "plt.ylabel('Feature', fontsize = 12)\n",
    "plt.yticks(range(len(coefs)), coefs['col'].values)\n",
    "plt.xlabel('Importance', fontsize = 12)\n",
    "plt.xticks(rotation = -45)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMpc = svm.LinearSVC(random_state = 421)\n",
    "SVMpc.fit(Xpc_train, ypc_train)\n",
    "ypc_pred = SVMpc.predict(Xpc_test)\n",
    "SVMpc.score(Xpc_test,ypc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\nSVM confusion matrix',\n",
    "    labels = ['Win', 'Loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "svm_wrong = svm_y[svm_y['test'] != svm_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[svm_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MLPClassifier()\n",
    "\n",
    "NN.fit(X_train, y_train)\n",
    "y_pred = NN.predict(X_test)\n",
    "NN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\nNN confusion matrix',\n",
    "    labels = ['Win', 'Loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "nn_wrong = nn_y[nn_y['test'] != nn_y['pred']]\n",
    "\n",
    "pre_dfs[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[nn_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_dict = {\n",
    "    'I' : 'o',\n",
    "    'C' : 'D',\n",
    "    'O' : '+',\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "    'Republican' : '#FF6661',\n",
    "    'Democrat' : '#5494F7',\n",
    "#     'Third party' : '#15DCDC',\n",
    "}\n",
    "\n",
    "alpha_dict = {\n",
    "    1 : 1.0,\n",
    "    0 : 0.2,\n",
    "}\n",
    "\n",
    "df_orig['marker'] = [marker_dict[df_orig.loc[i, 'cand_ici']] for i in list(df_orig.index)]\n",
    "df_orig['color'] = [color_dict[df_orig.loc[i, 'cand_pty_affiliation']] for \\\n",
    "                    i in list(df_orig.index)]\n",
    "df_orig['alpha'] = [alpha_dict[df_orig.loc[i, 'winner_flag']] for \\\n",
    "                    i in list(df_orig.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_contin = list(set([x.replace(' (R)', '').replace(' (D)', '') for x in contin.columns]))\n",
    "orig_contin = [x for x in orig_contin if x != 'r:d_funding_ratio']\n",
    "for i in range(len(orig_contin)):\n",
    "    for j in range(i + 1, len(orig_contin)):\n",
    "        start_df = deepcopy(df_orig)\n",
    "        for k in [i, j]:\n",
    "            median = start_df[orig_contin[k]].median()\n",
    "            std = start_df[orig_contin[k]].std()\n",
    "            start_df = start_df[\n",
    "                (start_df[orig_contin[k]] > (median - 3*std)) & \\\n",
    "                (start_df[orig_contin[k]] < (median + 3*std))\n",
    "            ]\n",
    "            start_df = start_df[start_df[orig_contin[k]] > 0]\n",
    "        if len(start_df) > 1:\n",
    "            plt.figure(figsize = (3, 3))\n",
    "            for ici in start_df['cand_ici'].value_counts().index:\n",
    "                lil_df = start_df[start_df['cand_ici'] == ici]\n",
    "                marker = marker_dict[ici]\n",
    "                for status in start_df['winner_flag'].value_counts().index:\n",
    "                    liller_df = lil_df[lil_df['winner_flag'] == status]\n",
    "                    alpha = alpha_dict[status]\n",
    "                    plt.scatter(\n",
    "                        liller_df[orig_contin[i]], \n",
    "                        liller_df[orig_contin[j]],\n",
    "                        color = liller_df['color'],\n",
    "                        alpha = alpha,\n",
    "                        marker = marker,\n",
    "                        s = 30,\n",
    "                    )\n",
    "            plt.xlabel(orig_contin[i], fontsize = 12)\n",
    "            plt.xticks([])\n",
    "            plt.ylabel(orig_contin[j], fontsize = 12)\n",
    "            plt.yticks([])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do ratio features\n",
    "# what are repeating pol_pty_contrib values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
