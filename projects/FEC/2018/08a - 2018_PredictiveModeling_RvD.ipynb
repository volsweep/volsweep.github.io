{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEC 2018 Campaign Finance: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state\n",
    "\n",
    "previously in politics\n",
    "\n",
    "proportion individ contrib from in-state\n",
    "\n",
    "party of prev officeholder \n",
    "\n",
    "primary results (is it open bc primary challenger beat incumbent)\n",
    "\n",
    "force predict one winner per race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from copy import deepcopy\n",
    "from itertools import combinations \n",
    "from matplotlib import patheffects as path_effects\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854\n",
      "852\n",
      "794\n",
      "673\n",
      "592\n",
      "LA_03\n",
      "LA_06\n",
      "LA_01\n",
      "CA_08\n",
      "WI_04\n",
      "WA_09\n",
      "CA_27\n",
      "CA_44\n",
      "PA_03\n",
      "568\n",
      "PA_17\n",
      "566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cand_id</th>\n",
       "      <th>cand_name</th>\n",
       "      <th>cand_ici</th>\n",
       "      <th>cand_pty_affiliation</th>\n",
       "      <th>ttl_receipts</th>\n",
       "      <th>trans_from_auth</th>\n",
       "      <th>ttl_disb</th>\n",
       "      <th>trans_to_auth</th>\n",
       "      <th>coh_bop</th>\n",
       "      <th>coh_cop</th>\n",
       "      <th>...</th>\n",
       "      <th>comm2__TEXAS FARM BUREAU (in-kind)</th>\n",
       "      <th>comm2__THE OORBEEK GROUP (in-kind)</th>\n",
       "      <th>comm2__THE OORBEEK GROUP (nonaffiliated)</th>\n",
       "      <th>comm2__THE WESTERVELT COMPANY PAC (nonaffiliated)</th>\n",
       "      <th>comm2__TWICE-BAKED BISTRO BIS (in-kind)</th>\n",
       "      <th>comm2__UNITED AIRLINES (in-kind)</th>\n",
       "      <th>comm2__UNITED PARCEL SERVICE (in-kind)</th>\n",
       "      <th>comm2__UNITED PARCEL SERVICE (nonaffiliated)</th>\n",
       "      <th>comm2__WASHINGTON NATIONALS (in-kind)</th>\n",
       "      <th>comm2__WINDOWS CATERING COMPANY (in-kind)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>H0AL02087</td>\n",
       "      <td>ROBY, MARTHA</td>\n",
       "      <td>I</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2573681.12</td>\n",
       "      <td>85734.19</td>\n",
       "      <td>2277448.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45450.72</td>\n",
       "      <td>341683.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>H0AL05163</td>\n",
       "      <td>BROOKS, MO</td>\n",
       "      <td>I</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1527246.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2006001.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1170937.70</td>\n",
       "      <td>692181.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>H0AR01083</td>\n",
       "      <td>CRAWFORD, ERIC ALAN RICK</td>\n",
       "      <td>I</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1019464.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>966616.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258577.00</td>\n",
       "      <td>311424.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>H0AR03055</td>\n",
       "      <td>WOMACK, STEVE</td>\n",
       "      <td>I</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1211826.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1218424.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1165816.16</td>\n",
       "      <td>1159218.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>H0AZ01259</td>\n",
       "      <td>GOSAR, PAUL DR.</td>\n",
       "      <td>I</td>\n",
       "      <td>Republican</td>\n",
       "      <td>588764.42</td>\n",
       "      <td>16108.36</td>\n",
       "      <td>575157.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107593.03</td>\n",
       "      <td>121199.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cand_id                 cand_name cand_ici cand_pty_affiliation  \\\n",
       "0  H0AL02087              ROBY, MARTHA        I           Republican   \n",
       "1  H0AL05163                BROOKS, MO        I           Republican   \n",
       "3  H0AR01083  CRAWFORD, ERIC ALAN RICK        I           Republican   \n",
       "4  H0AR03055             WOMACK, STEVE        I           Republican   \n",
       "5  H0AZ01259           GOSAR, PAUL DR.        I           Republican   \n",
       "\n",
       "   ttl_receipts  trans_from_auth    ttl_disb  trans_to_auth     coh_bop  \\\n",
       "0    2573681.12         85734.19  2277448.83            0.0    45450.72   \n",
       "1    1527246.16             0.00  2006001.97            0.0  1170937.70   \n",
       "3    1019464.16             0.00   966616.64            0.0   258577.00   \n",
       "4    1211826.66             0.00  1218424.03            0.0  1165816.16   \n",
       "5     588764.42         16108.36   575157.87            0.0   107593.03   \n",
       "\n",
       "      coh_cop  ...  comm2__TEXAS FARM BUREAU (in-kind)  \\\n",
       "0   341683.01  ...                                 0.0   \n",
       "1   692181.51  ...                                 0.0   \n",
       "3   311424.52  ...                                 0.0   \n",
       "4  1159218.79  ...                                 0.0   \n",
       "5   121199.58  ...                                 0.0   \n",
       "\n",
       "   comm2__THE OORBEEK GROUP (in-kind)  \\\n",
       "0                                 0.0   \n",
       "1                                 0.0   \n",
       "3                                 0.0   \n",
       "4                                 0.0   \n",
       "5                                 0.0   \n",
       "\n",
       "   comm2__THE OORBEEK GROUP (nonaffiliated)  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "5                                       0.0   \n",
       "\n",
       "   comm2__THE WESTERVELT COMPANY PAC (nonaffiliated)  \\\n",
       "0                                             2500.0   \n",
       "1                                             1000.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "5                                                0.0   \n",
       "\n",
       "   comm2__TWICE-BAKED BISTRO BIS (in-kind)  comm2__UNITED AIRLINES (in-kind)  \\\n",
       "0                                      0.0                               0.0   \n",
       "1                                      0.0                               0.0   \n",
       "3                                      0.0                               0.0   \n",
       "4                                      0.0                               0.0   \n",
       "5                                      0.0                               0.0   \n",
       "\n",
       "   comm2__UNITED PARCEL SERVICE (in-kind)  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "5                                     0.0   \n",
       "\n",
       "  comm2__UNITED PARCEL SERVICE (nonaffiliated)  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "5                                          0.0   \n",
       "\n",
       "   comm2__WASHINGTON NATIONALS (in-kind)  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "5                                    0.0   \n",
       "\n",
       "   comm2__WINDOWS CATERING COMPANY (in-kind)  \n",
       "0                                        0.0  \n",
       "1                                        0.0  \n",
       "3                                        0.0  \n",
       "4                                        0.0  \n",
       "5                                        0.0  \n",
       "\n",
       "[5 rows x 1343 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_orig = pd.read_csv('data/04bii_cand_cleaned.csv')\n",
    "\n",
    "# include only house elections\n",
    "cand_orig = cand_orig[cand_orig['position'] == 'H']\n",
    "print(len(cand_orig))\n",
    "\n",
    "# exclude races where Third party won\n",
    "cand_orig = cand_orig[cand_orig['contest'] != 'MP_00']\n",
    "print(len(cand_orig))\n",
    "\n",
    "# exclude Third Party candidates for modeling for now\n",
    "cand_orig = cand_orig[cand_orig['cand_pty_affiliation'] != 'Third party']\n",
    "print(len(cand_orig))\n",
    "\n",
    "# exclude open seat races; model requires one incumbent and one challenger\n",
    "cand_orig = cand_orig[cand_orig['cand_ici'] != 'O']\n",
    "print(len(cand_orig))\n",
    "\n",
    "# exclude solo candidates\n",
    "solos = list(cand_orig['contest'].value_counts()[cand_orig['contest'].value_counts() == 1].index)\n",
    "for which in solos:\n",
    "    cand_orig = cand_orig[cand_orig['contest'] != which]\n",
    "print(len(cand_orig))\n",
    "\n",
    "# exclude races with more than one candidate from each party\n",
    "drops = []\n",
    "for race in list(cand_orig['contest'].value_counts().index):\n",
    "    lil_cand = cand_orig[cand_orig['contest'] == race]\n",
    "    orig = len(lil_cand)\n",
    "    lil_cand.drop_duplicates(['cand_pty_affiliation'], inplace = True)\n",
    "    new = len(lil_cand)\n",
    "    if orig != new:\n",
    "        drops.append(race)\n",
    "        print(race)\n",
    "        \n",
    "mask = [False if cand_orig.loc[i, 'contest'] in drops else True for i in list(cand_orig.index)]\n",
    "cand_orig = cand_orig[mask]\n",
    "print(len(cand_orig))\n",
    "\n",
    "# exclude races with more than one incumbent (i.e. gerrymandering cases)\n",
    "drops = []\n",
    "for race in list(cand_orig['contest'].value_counts().index):\n",
    "    lil_cand = cand_orig[cand_orig['contest'] == race]\n",
    "    orig = len(lil_cand)\n",
    "    lil_cand.drop_duplicates(['cand_ici'], inplace = True)\n",
    "    new = len(lil_cand)\n",
    "    if orig != new:\n",
    "        drops.append(race)\n",
    "        print(race)\n",
    "        \n",
    "mask = [False if cand_orig.loc[i, 'contest'] in drops else True for i in list(cand_orig.index)]\n",
    "cand_orig = cand_orig[mask]\n",
    "print(len(cand_orig))\n",
    "    \n",
    "cand_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group 01    266\n",
       "Group 02    184\n",
       "Group 04    114\n",
       "Group 10      2\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_orig['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flag each contest winner\n",
    "# winner set constructed by manually reviewing each contest in Ballotpedia \n",
    "winner_cand = pd.read_csv('data/winners_2018.csv')\n",
    "winner_dict = dict(zip(winner_cand['contest'], winner_cand['cand_id']))\n",
    "\n",
    "cand_orig['winner_flag'] = [1 if cand_orig.loc[i, 'cand_id'] in list(winner_dict.values()) else \\\n",
    "                     0 for i in list(cand_orig.index)]\n",
    "\n",
    "set(cand_orig['winner_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand = cand_orig.drop([\n",
    "    'cand_id',\n",
    "    'cand_name',\n",
    "    'cvg_end_dt',\n",
    "#     'cand_class', \n",
    "#     'contest', # keep for join later\n",
    "    'cand_loans', \n",
    "    'other_loans',\n",
    "    'cand_office_district',\n",
    "    'cand_office_st',\n",
    "    'ttl_disb',\n",
    "    'coh_cop',\n",
    "    'cand_loan_repay',\n",
    "    'other_loan_repay',\n",
    "    'indiv_refunds',\n",
    "    'cmte_refunds',\n",
    "    'trans_to_auth',\n",
    "    'debts_owed_by', # include? or time machine issue\n",
    "    'position',\n",
    "    'type',\n",
    "], axis = 1)\n",
    "\n",
    "if len(cand.isnull().sum()[cand.isnull().sum() > 0].sort_values()) == 0:\n",
    "    print('no nulls')\n",
    "else:\n",
    "    print('check nulls')\n",
    "    \n",
    "cand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummify = [\n",
    "    'cand_ici',\n",
    "    'cand_pty_affiliation',\n",
    "#     'position'\n",
    "]\n",
    "\n",
    "for col in dummify:\n",
    "    cand = pd.concat([\n",
    "        cand.drop([col], axis = 1), \n",
    "        pd.get_dummies(cand[col])\n",
    "    ], axis = 1)\n",
    "    \n",
    "cand.rename(columns={\n",
    "    'C' : 'challenger',\n",
    "    'I' : 'incumbent',\n",
    "    'O' : 'open seat',\n",
    "#     'H' : 'House',\n",
    "#     'S' : 'Senate',\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "republicans = cand[cand['Republican'] == 1]\n",
    "republicans.columns = [x + ' (R)' if x != 'contest' else x for x in republicans.columns]\n",
    "republicans.set_index('contest', inplace = True)\n",
    "\n",
    "democrats = cand[cand['Republican'] == 0]\n",
    "democrats.columns = [x + ' (D)' if x != 'contest' else x for x in democrats.columns]\n",
    "democrats.set_index('contest', inplace = True)\n",
    "\n",
    "pre_cands = republicans.join(democrats, on = 'contest')\n",
    "pre_cands.reset_index(drop = False, inplace = True)\n",
    "\n",
    "pre_cands.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_cands['r:d_funding_ratio'] = pre_cands['ttl_receipts (R)']/pre_cands['ttl_receipts (D)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contin_cols = [\n",
    "    'ttl_receipts (R)',\n",
    "    'trans_from_auth (R)',\n",
    "    'coh_bop (R)',\n",
    "    'cand_contrib (R)',\n",
    "    'ttl_indiv_contrib (R)',\n",
    "    'other_pol_cmte_contrib (R)',\n",
    "    'pol_pty_contrib (R)',\n",
    "    '(for) sum (R)',\n",
    "    '(for) sum (D)',\n",
    "    '(for) count (R)',\n",
    "    '(for) count (D)',\n",
    "    '(against) sum (R)',\n",
    "    '(against) sum (D)',\n",
    "    '(against) count (R)',\n",
    "    '(against) count (D)',\n",
    "    '(nonaffiliated) sum (R)',\n",
    "    '(nonaffiliated) sum (D)',\n",
    "    '(nonaffiliated) count (R)',\n",
    "    '(nonaffiliated) count (D)',\n",
    "    '(in-kind) sum (R)',\n",
    "    '(in-kind) sum (D)',\n",
    "    '(in-kind) count (R)',\n",
    "    '(in-kind) count (D)',\n",
    "    '(coord pty exp) sum (R)',\n",
    "    '(coord pty exp) sum (D)',\n",
    "    '(coord pty exp) count (R)',\n",
    "    '(coord pty exp) count (D)',\n",
    "    'ttl_receipts (D)',\n",
    "    'trans_from_auth (D)',\n",
    "    'coh_bop (D)',\n",
    "    'cand_contrib (D)',\n",
    "    'ttl_indiv_contrib (D)',\n",
    "    'other_pol_cmte_contrib (D)',\n",
    "    'pol_pty_contrib (D)',\n",
    "    'r:d_funding_ratio',\n",
    "    \n",
    "]\n",
    "\n",
    "contin = pre_cands[contin_cols]\n",
    "\n",
    "contin_s = pd.DataFrame(\n",
    "    MinMaxScaler().fit_transform(contin), \n",
    "    index = pre_cands.index, \n",
    "    columns = contin_cols,\n",
    ")\n",
    "\n",
    "the_rest = [x for x in pre_cands.columns if x not in contin_s.columns]\n",
    "\n",
    "cands = pd.concat([contin_s, pre_cands[the_rest]], axis = 1)\n",
    "\n",
    "cands.columns = [x.replace('Republican', 'republican').replace('Democrat', 'democrat') for x in cands.columns]\n",
    "\n",
    "cands = cands[sorted(cands.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands.drop([\n",
    "    'challenger (D)',\n",
    "    'challenger (R)',\n",
    "    'contest',\n",
    "    'democrat (D)',\n",
    "    'democrat (R)',\n",
    "    'incumbent (D)',\n",
    "#     'maxfunding_flag (D)',\n",
    "#     'maxfunding_flag (R)',\n",
    "    'republican (D)',\n",
    "    'republican (R)',\n",
    "    'winner_flag (D)',\n",
    "    \n",
    "], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partisan donors -- only gave to one party (listed columns are all 0s)\n",
    "nones = list(cands.sum()[cands.sum() == 0].index)\n",
    "nones = [x.split('__')[1] for x in nones]\n",
    "list(nones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = cands.sum()[cands.sum() == 0].index\n",
    "\n",
    "for which in drops:\n",
    "    cands.drop(which, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 16))\n",
    "corr_mat = np.tril(cands.corr(), k = -1)\n",
    "ticks = [x.split('__')[1] if ('__' in x) else x for x in cands.columns]\n",
    "sns.heatmap(corr_mat, cmap = 'PRGn', vmin = -1, vmax = 1)\n",
    "plt.title('2018 U.S. House of Representatives elections:\\nFeature correlation', fontsize = 14)\n",
    "plt.xticks(\n",
    "    np.arange(0.5, len(cands.columns), 1), \n",
    "    ticks, \n",
    "    fontsize = 7, \n",
    "    rotation = 90\n",
    ")\n",
    "plt.yticks(\n",
    "    np.arange(0.5, len(cands.columns), 1), \n",
    "    ticks, \n",
    "    fontsize = 7, \n",
    "    rotation = 0\n",
    ")\n",
    "plt.xlim([0, len(cands.columns)])\n",
    "plt.ylim([len(cands.columns), 0])\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = deepcopy(cands)\n",
    "X.drop(['winner_flag (R)'], axis = 1, inplace = True)\n",
    "\n",
    "# target is whether incumbent wins\n",
    "y = cands[['winner_flag (R)']]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X[y['winner_flag (R)'] == 1], \n",
    "    y[y['winner_flag (R)'] == 1], \n",
    "    random_state = 421, \n",
    "    test_size = 0.33\n",
    ")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X[y['winner_flag (R)'] == 0], \n",
    "    y[y['winner_flag (R)'] == 0], \n",
    "    random_state = 421, \n",
    "    test_size = 0.33\n",
    ")\n",
    "\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "\n",
    "all_four = [\n",
    "    [X_train1, X_train2],\n",
    "    [X_test1, X_test2],\n",
    "    [y_train1, y_train2],\n",
    "    [y_test1, y_test2],\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    X_train = pd.concat([X_train, all_four[0][i]], axis = 0)\n",
    "    X_test = pd.concat([X_test, all_four[1][i]], axis = 0)\n",
    "    y_train = pd.concat([y_train, all_four[2][i]], axis = 0)\n",
    "    y_test = pd.concat([y_test, all_four[3][i]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    confmat, \n",
    "    title = 'Confusion Matrix', \n",
    "    labels = ['Win', 'Loss'], \n",
    "    cmap = plt.cm.Blues,\n",
    "):\n",
    "\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.imshow(\n",
    "        confmat, \n",
    "        interpolation = 'nearest', \n",
    "        cmap = cmap, \n",
    "    )\n",
    "\n",
    "    plt.grid(b = False)\n",
    "\n",
    "    width, height = confmat.shape\n",
    "    \n",
    "    tick_marks = np.arange(width)\n",
    "    plt.xticks(tick_marks, labels, fontsize = 14)\n",
    "    plt.yticks(tick_marks, labels, fontsize = 14)\n",
    "    plt.scatter(0, 0, color = (0,0,0,0))\n",
    "\n",
    "    plt.title(title, fontsize = 14)\n",
    "    plt.ylabel('Actual', fontsize = 14)\n",
    "    plt.xlabel('Prediction', fontsize = 14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(\n",
    "                str(confmat[x][y]), \n",
    "                xy = (y, x), \n",
    "                horizontalalignment = 'center', \n",
    "                verticalalignment = 'center', \n",
    "                color = 'white', \n",
    "                fontsize = 40,\n",
    "            ).set_path_effects(\n",
    "                [\n",
    "                    path_effects.Stroke(linewidth = 1, \n",
    "                                        foreground = 'black'\n",
    "                                       ), \n",
    "                    path_effects.Normal()\n",
    "                ]\n",
    "            )\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaÃ¯ve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_inc = [1 if (cands.loc[i, 'incumbent (R)'] == 1) else 0 for i in list(cands.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(cands['winner_flag (R)'], y_pred_inc),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    NaÃ¯ve model confusion matrix\\n--> choose incumbent',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred_inc), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "inc_wrong = inc_y[inc_y['test'] != inc_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[inc_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fund = [1 if (pre_cands.loc[i, 'r:d_funding_ratio'] > 1) else 0 for i in list(cands.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(cands['winner_flag (R)'], y_pred_fund),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    NaÃ¯ve model confusion matrix\\n--> choose higher funding',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred_fund), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "fund_wrong = fund_y[fund_y['test'] != fund_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[fund_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(cv = 11, random_state = 421)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Logistic regression confusion matrix',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "lr_wrong = lr_y[lr_y['test'] != lr_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[lr_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(zip(X, lr.coef_[0]), columns = ['col', 'coef'])\n",
    "coefs['abs_coef'] = [abs(x) for x in coefs['coef']]\n",
    "\n",
    "coefs.sort_values(['abs_coef'], ascending = False, inplace = True)\n",
    "coefs['color'] = (coefs['coef'] == coefs['abs_coef'])\n",
    "coefs['color'] = ['green' if x == True else 'purple' for x in coefs['color']]\n",
    "coefs.drop(['abs_coef'], axis = 1, inplace = True)\n",
    "coefs = coefs[::-1]\n",
    "coefs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 24))\n",
    "plt.barh(\n",
    "    coefs.index, \n",
    "    coefs['coef'].apply(lambda x: abs(x)), \n",
    "    color = coefs['color'], \n",
    "    alpha = 0.8\n",
    ")\n",
    "\n",
    "plt.title('2018 U.S. House of Representatives elections:\\n\\\n",
    "Logistic regression feature importance', fontsize = 14)\n",
    "plt.ylabel('Feature', fontsize = 12)\n",
    "plt.yticks(range(len(coefs)), coefs['col'].values)\n",
    "plt.xlabel('Coefficient', fontsize = 12)\n",
    "# plt.xticks()\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=421)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Random forest confusion matrix',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "rfc_wrong = rfc_y[rfc_y['test'] != rfc_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[rfc_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(zip(X, rfc.feature_importances_), columns = ['col', 'coef'])\n",
    "coefs['abs_coef'] = [abs(x) for x in coefs['coef']]\n",
    "\n",
    "coefs.sort_values(['abs_coef'], ascending = False, inplace = True)\n",
    "coefs['color'] = (coefs['coef'] == coefs['abs_coef'])\n",
    "coefs['color'] = ['green' if x == True else 'purple' for x in coefs['color']]\n",
    "coefs.drop(['abs_coef'], axis = 1, inplace = True)\n",
    "coefs = coefs[::-1]\n",
    "coefs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 24))\n",
    "plt.barh(\n",
    "    coefs.index, \n",
    "    coefs['coef'].apply(lambda x: abs(x)), \n",
    "    color = coefs['color'], \n",
    "    alpha = 0.8\n",
    ")\n",
    "\n",
    "plt.title('2018 House of Representatives elections:\\n\\\n",
    "Random forest feature importance', fontsize = 14)\n",
    "plt.ylabel('Feature', fontsize = 12)\n",
    "plt.yticks(range(len(coefs)), coefs['col'].values)\n",
    "plt.xlabel('Importance', fontsize = 12)\n",
    "plt.xticks(rotation = -45)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.LinearSVC(random_state = 421)\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "SVM.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\nSVM confusion matrix',\n",
    "    labels = ['Win', 'Loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "svm_wrong = svm_y[svm_y['test'] != svm_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[svm_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MLPClassifier()\n",
    "\n",
    "NN.fit(X_train, y_train)\n",
    "y_pred = NN.predict(X_test)\n",
    "NN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\nNN confusion matrix',\n",
    "    labels = ['Win', 'Loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "nn_wrong = nn_y[nn_y['test'] != nn_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[nn_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "candspc = cands.drop(['winner_flag (R)'], axis = 1)\n",
    "\n",
    "pca = PCA(n_components = len(candspc.columns))\n",
    "\n",
    "pc = pca.fit(candspc)\n",
    "# pccand = pd.DataFrame(\n",
    "#     data = pc, \n",
    "# #     columns = ['principal component 1', 'principal component 2'], \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(candspc.columns)), pc.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpc = deepcopy(candspc)\n",
    "\n",
    "# target is whether incumbent wins\n",
    "ypc = cands[['winner_flag (R)']]\n",
    "\n",
    "Xpc_train1, Xpc_test1, ypc_train1, ypc_test1 = train_test_split(\n",
    "    Xpc[ypc['winner_flag (R)'] == 1], \n",
    "    ypc[ypc['winner_flag (R)'] == 1], \n",
    "    random_state = 421, \n",
    "    test_size = 0.33\n",
    ")\n",
    "\n",
    "Xpc_train2, Xpc_test2, ypc_train2, ypc_test2 = train_test_split(\n",
    "    Xpc[ypc['winner_flag (R)'] == 0], \n",
    "    ypc[ypc['winner_flag (R)'] == 0], \n",
    "    random_state = 421, \n",
    "    test_size = 0.33\n",
    ")\n",
    "\n",
    "Xpc_train = pd.DataFrame()\n",
    "Xpc_test = pd.DataFrame()\n",
    "ypc_train = pd.DataFrame()\n",
    "ypc_test = pd.DataFrame()\n",
    "\n",
    "all_four = [\n",
    "    [Xpc_train1, Xpc_train2],\n",
    "    [Xpc_test1, Xpc_test2],\n",
    "    [ypc_train1, ypc_train2],\n",
    "    [ypc_test1, ypc_test2],\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    Xpc_train = pd.concat([Xpc_train, all_four[0][i]], axis = 0)\n",
    "    Xpc_test = pd.concat([Xpc_test, all_four[1][i]], axis = 0)\n",
    "    ypc_train = pd.concat([ypc_train, all_four[2][i]], axis = 0)\n",
    "    ypc_test = pd.concat([ypc_test, all_four[3][i]], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpc = LogisticRegressionCV(cv = 11, random_state = 421)\n",
    "\n",
    "lrpc.fit(Xpc_train, ypc_train)\n",
    "y_pred = lrpc.predict(Xpc_test)\n",
    "lrpc.score(Xpc_test, ypc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Logistic regression confusion matrix',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "lr_wrong = lr_y[lr_y['test'] != lr_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[lr_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(zip(Xpc, lrpc.coef_[0]), columns = ['col', 'coef'])\n",
    "coefs['abs_coef'] = [abs(x) for x in coefs['coef']]\n",
    "\n",
    "coefs.sort_values(['abs_coef'], ascending = False, inplace = True)\n",
    "coefs['color'] = (coefs['coef'] == coefs['abs_coef'])\n",
    "coefs['color'] = ['green' if x == True else 'purple' for x in coefs['color']]\n",
    "coefs.drop(['abs_coef'], axis = 1, inplace = True)\n",
    "coefs = coefs[::-1]\n",
    "coefs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 24))\n",
    "plt.barh(\n",
    "    coefs.index, \n",
    "    coefs['coef'].apply(lambda x: abs(x)), \n",
    "    color = coefs['color'], \n",
    "    alpha = 0.8\n",
    ")\n",
    "\n",
    "plt.title('2018 U.S. House of Representatives elections:\\n\\\n",
    "Logistic regression feature importance', fontsize = 14)\n",
    "plt.ylabel('Feature', fontsize = 12)\n",
    "plt.yticks(range(len(coefs)), coefs['col'].values)\n",
    "plt.xlabel('Coefficient', fontsize = 12)\n",
    "# plt.xticks()\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcpc = RandomForestClassifier(random_state=421)\n",
    "\n",
    "rfcpc.fit(Xpc_train, ypc_train)\n",
    "ypc_pred = rfcpc.predict(Xpc_test)\n",
    "rfcpc.score(Xpc_test, ypc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(ypc_test, ypc_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\n\\\n",
    "    Random forest confusion matrix',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcpc_y = pd.DataFrame(\n",
    "    zip(ypc_test['winner_flag (R)'], ypc_pred), \n",
    "    index = ypc_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "rfcpc_wrong = rfcpc_y[rfcpc_y['test'] != rfcpc_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[rfcpc_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(zip(Xpc, rfcpc.feature_importances_), columns = ['col', 'coef'])\n",
    "coefs['abs_coef'] = [abs(x) for x in coefs['coef']]\n",
    "\n",
    "coefs.sort_values(['abs_coef'], ascending = False, inplace = True)\n",
    "coefs['color'] = (coefs['coef'] == coefs['abs_coef'])\n",
    "coefs['color'] = ['green' if x == True else 'purple' for x in coefs['color']]\n",
    "coefs.drop(['abs_coef'], axis = 1, inplace = True)\n",
    "coefs = coefs[::-1]\n",
    "coefs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 24))\n",
    "plt.barh(\n",
    "    coefs.index, \n",
    "    coefs['coef'].apply(lambda x: abs(x)), \n",
    "    color = coefs['color'], \n",
    "    alpha = 0.8\n",
    ")\n",
    "\n",
    "plt.title('2018 House of Representatives elections:\\n\\\n",
    "Random forest feature importance', fontsize = 14)\n",
    "plt.ylabel('Feature', fontsize = 12)\n",
    "plt.yticks(range(len(coefs)), coefs['col'].values)\n",
    "plt.xlabel('Importance', fontsize = 12)\n",
    "plt.xticks(rotation = -45)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMpc = svm.LinearSVC(random_state = 421)\n",
    "SVMpc.fit(Xpc_train, ypc_train)\n",
    "ypc_pred = SVMpc.predict(Xpc_test)\n",
    "SVMpc.score(Xpc_test,ypc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\nSVM confusion matrix',\n",
    "    labels = ['Win', 'Loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "svm_wrong = svm_y[svm_y['test'] != svm_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[svm_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MLPClassifier()\n",
    "\n",
    "NN.fit(X_train, y_train)\n",
    "y_pred = NN.predict(X_test)\n",
    "NN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    title = '2018 U.S. House of Representatives elections:\\nNN confusion matrix',\n",
    "    labels = ['Win', 'Loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y = pd.DataFrame(\n",
    "    zip(y_test['winner_flag (R)'], y_pred), \n",
    "    index = y_test.index, \n",
    "    columns = ['test', 'pred'],\n",
    ")\n",
    "\n",
    "nn_wrong = nn_y[nn_y['test'] != nn_y['pred']]\n",
    "\n",
    "pre_cands[[\n",
    "    'contest', \n",
    "    'ttl_receipts (R)',\n",
    "    'ttl_receipts (D)',\n",
    "    'winner_flag (R)'\n",
    "]].iloc[nn_wrong.index].sort_values(['ttl_receipts (R)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_dict = {\n",
    "    'I' : 'o',\n",
    "    'C' : 'D',\n",
    "    'O' : '+',\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "    'Republican' : '#FF6661',\n",
    "    'Democrat' : '#5494F7',\n",
    "#     'Third party' : '#15DCDC',\n",
    "}\n",
    "\n",
    "alpha_dict = {\n",
    "    1 : 1.0,\n",
    "    0 : 0.2,\n",
    "}\n",
    "\n",
    "cand_orig['marker'] = [marker_dict[cand_orig.loc[i, 'cand_ici']] for i in list(cand_orig.index)]\n",
    "cand_orig['color'] = [color_dict[cand_orig.loc[i, 'cand_pty_affiliation']] for \\\n",
    "                    i in list(cand_orig.index)]\n",
    "cand_orig['alpha'] = [alpha_dict[cand_orig.loc[i, 'winner_flag']] for \\\n",
    "                    i in list(cand_orig.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_contin = list(set([x.replace(' (R)', '').replace(' (D)', '') for x in contin.columns]))\n",
    "orig_contin = [x for x in orig_contin if x != 'r:d_funding_ratio']\n",
    "for i in range(len(orig_contin)):\n",
    "    for j in range(i + 1, len(orig_contin)):\n",
    "        start_cand = deepcopy(cand_orig)\n",
    "        for k in [i, j]:\n",
    "            median = start_cand[orig_contin[k]].median()\n",
    "            std = start_cand[orig_contin[k]].std()\n",
    "            start_cand = start_cand[\n",
    "                (start_cand[orig_contin[k]] > (median - 3*std)) & \\\n",
    "                (start_cand[orig_contin[k]] < (median + 3*std))\n",
    "            ]\n",
    "            start_cand = start_cand[start_cand[orig_contin[k]] > 0]\n",
    "        if len(start_cand) > 1:\n",
    "            plt.figure(figsize = (3, 3))\n",
    "            for ici in start_cand['cand_ici'].value_counts().index:\n",
    "                lil_cand = start_cand[start_cand['cand_ici'] == ici]\n",
    "                marker = marker_dict[ici]\n",
    "                for status in start_cand['winner_flag'].value_counts().index:\n",
    "                    liller_cand = lil_cand[lil_cand['winner_flag'] == status]\n",
    "                    alpha = alpha_dict[status]\n",
    "                    plt.scatter(\n",
    "                        liller_cand[orig_contin[i]], \n",
    "                        liller_cand[orig_contin[j]],\n",
    "                        color = liller_cand['color'],\n",
    "                        alpha = alpha,\n",
    "                        marker = marker,\n",
    "                        s = 30,\n",
    "                    )\n",
    "            plt.xlabel(orig_contin[i], fontsize = 12)\n",
    "            plt.xticks([])\n",
    "            plt.ylabel(orig_contin[j], fontsize = 12)\n",
    "            plt.yticks([])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do ratio features\n",
    "# what are repeating pol_pty_contrib values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
